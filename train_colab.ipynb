{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rebu4mzEYJ0U"
      },
      "source": [
        "# In-Context Learning Training Notebook\n",
        "This notebook trains transformer models for in-context learning on Google Colab.\n",
        "\n",
        "**Setup Instructions:**\n",
        "1. Runtime → Change runtime type → GPU (T4, A100, or V100)\n",
        "2. Run cells sequentially\n",
        "3. Authenticate with Weights & Biases when prompted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVShoBRuYJ0X"
      },
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "**Note:** This notebook has been updated to use modern package versions compatible with current Google Colab environments (Python 3.10+, PyTorch 2.x). The original code was written for PyTorch 1.11, but the training code should work with newer versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7D5mH0YJ0X",
        "outputId": "8f8d85cf-e7cd-4a39-e086-12ccb9a4a5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 11 05:26:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKYQ9xNlYJ0Y",
        "outputId": "6ef7c3bd-5784-45bb-879a-5dc2dafe4bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Installing packages...\n",
            "\n",
            "✓ PyTorch already installed: 2.8.0+cu126\n",
            "\n",
            "============================================================\n",
            "✓ All required packages installed successfully!\n",
            "============================================================\n",
            "\n",
            "Package Versions:\n",
            "  PyTorch: 2.8.0+cu126\n",
            "  Transformers: 4.57.1\n",
            "  Wandb: 0.22.3\n",
            "\n",
            "GPU Information:\n",
            "  CUDA available: True\n",
            "  CUDA version: 12.6\n",
            "  GPU: NVIDIA A100-SXM4-40GB\n",
            "  GPU Memory: 42.47 GB\n",
            "\n",
            "Ready to proceed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "# Note: Colab comes with PyTorch pre-installed, we'll use compatible versions\n",
        "\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"Installing packages...\\n\")\n",
        "\n",
        "# Install core packages (quinine is NOT needed for notebook - only for CLI)\n",
        "%pip install -q transformers>=4.30.0\n",
        "%pip install -q wandb\n",
        "%pip install -q xgboost\n",
        "%pip install -q funcy\n",
        "%pip install -q matplotlib seaborn tqdm\n",
        "\n",
        "# PyTorch usually comes pre-installed in Colab, but ensure it's available\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"✓ PyTorch already installed: {torch.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Installing PyTorch...\")\n",
        "    %pip install -q torch torchvision torchaudio\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ All required packages installed successfully!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify key packages\n",
        "import torch\n",
        "import transformers\n",
        "import wandb\n",
        "\n",
        "print(f\"\\nPackage Versions:\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Wandb: {wandb.__version__}\")\n",
        "\n",
        "print(f\"\\nGPU Information:\")\n",
        "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\" No GPU detected! Make sure to enable GPU: Runtime → Change runtime type → T4 GPU\")\n",
        "\n",
        "print(\"\\nReady to proceed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCFcg0LZYJ0Y"
      },
      "source": [
        "## 2. Clone Repository\n",
        "**Option A:** Clone from GitHub (replace with your repo URL)\n",
        "\n",
        "**Option B:** Upload files manually or mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_XSA9IaYJ0Y",
        "outputId": "ed15139b-4942-47f3-de7b-4e10061d3569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository from https://github.com/hingma/in-context-learning.git...\n",
            "✓ Repository cloned successfully\n",
            "/content/in-context-learning\n"
          ]
        }
      ],
      "source": [
        "# Option A: Clone from GitHub\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Replace with your repository URL\n",
        "REPO_URL = \"https://github.com/hingma/in-context-learning.git\"  # UPDATE THIS!\n",
        "\n",
        "if not os.path.exists(\"in-context-learning\"):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    result = subprocess.run([\"git\", \"clone\", REPO_URL], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"✓ Repository cloned successfully\")\n",
        "    else:\n",
        "        print(f\"Error cloning repository: {result.stderr}\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists\")\n",
        "\n",
        "%cd in-context-learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64kHdFH-YJ0Z"
      },
      "outputs": [],
      "source": [
        "# Option B: Mount Google Drive (uncomment if needed)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd /content/drive/MyDrive/in-context-learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcdiBuHqYJ0Z"
      },
      "source": [
        "## 3. Setup Weights & Biases (W&B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "WvoM1jsgYJ0Z",
        "outputId": "90b9fb7c-c3ff-4ca4-d931-73ef2f324ea3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/in-context-learning/wandb/run-20251111_060724-ik3j997b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/moxintang-ucb/in-context-learning/runs/ik3j997b' target=\"_blank\">youthful-planet-2</a></strong> to <a href='https://wandb.ai/moxintang-ucb/in-context-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/moxintang-ucb/in-context-learning' target=\"_blank\">https://wandb.ai/moxintang-ucb/in-context-learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/moxintang-ucb/in-context-learning/runs/ik3j997b' target=\"_blank\">https://wandb.ai/moxintang-ucb/in-context-learning/runs/ik3j997b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ W&B authenticated\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to W&B (you'll need to paste your API key)\n",
        "wandb.login()\n",
        "wandb.init(settings=wandb.Settings(init_timeout=300))\n",
        "print(\"✓ W&B authenticated\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJyfvnPwYJ0Z"
      },
      "source": [
        "## 4. Configure Training Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9zAsaRwYJ0Z",
        "outputId": "f860781e-d02b-4c80-96b1-dd63c3f4af61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Auto-detected W&B username: moxintang\n",
            "\n",
            "✓ W&B entity set to: moxintang\n",
            "\n",
            "============================================================\n",
            "Training Configuration:\n",
            "============================================================\n",
            "model:\n",
            "  family: gpt2\n",
            "  n_dims: 20\n",
            "  n_embd: 256\n",
            "  n_head: 8\n",
            "  n_layer: 12\n",
            "  n_positions: 101\n",
            "out_dir: ./models\n",
            "test_run: true\n",
            "training:\n",
            "  batch_size: 64\n",
            "  curriculum:\n",
            "    dims:\n",
            "      end: 20\n",
            "      inc: 1\n",
            "      interval: 2000\n",
            "      start: 5\n",
            "    points:\n",
            "      end: 41\n",
            "      inc: 2\n",
            "      interval: 2000\n",
            "      start: 11\n",
            "  data: gaussian\n",
            "  keep_every_steps: 10000\n",
            "  learning_rate: 0.0001\n",
            "  num_tasks: null\n",
            "  num_training_examples: null\n",
            "  resume_id: null\n",
            "  save_every_steps: 1000\n",
            "  task: linear_regression\n",
            "  task_kwargs: {}\n",
            "  train_steps: 50000\n",
            "wandb:\n",
            "  entity: moxintang\n",
            "  log_every_steps: 10\n",
            "  name: colab_linear_regression\n",
            "  notes: Training on Google Colab\n",
            "  project: cs182-icl-experiments\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "# Auto-detect W&B username (since we already logged in)\n",
        "try:\n",
        "    api = wandb.Api()\n",
        "    wandb_entity = api.viewer.username\n",
        "    print(f\"✓ Auto-detected W&B username: {wandb_entity}\")\n",
        "except Exception as e:\n",
        "    wandb_entity = \"your-wandb-entity\"  # Fallback\n",
        "    print(f\"⚠️  Could not auto-detect W&B username: {e}\")\n",
        "    print(\"   Please update config['wandb']['entity'] manually below!\")\n",
        "\n",
        "# Training configuration\n",
        "config = {\n",
        "    \"out_dir\": \"./models\",\n",
        "    \"test_run\": True,  # Set to True for quick test (100 steps)\n",
        "\n",
        "    \"model\": {\n",
        "        \"family\": \"gpt2\",  # or \"lstm\"\n",
        "        \"n_dims\": 20,\n",
        "        \"n_positions\": 101,\n",
        "        \"n_embd\": 256,\n",
        "        \"n_layer\": 12,\n",
        "        \"n_head\": 8,\n",
        "    },\n",
        "\n",
        "    \"training\": {\n",
        "        \"task\": \"linear_regression\",  # Options: linear_regression, sparse_linear_regression,\n",
        "                                       # linear_classification, relu_2nn_regression, decision_tree\n",
        "        \"task_kwargs\": {},\n",
        "        \"num_tasks\": None,\n",
        "        \"num_training_examples\": None,\n",
        "        \"data\": \"gaussian\",\n",
        "        \"batch_size\": 64,\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"train_steps\": 50000,  # Adjust based on your needs\n",
        "        \"save_every_steps\": 1000,\n",
        "        \"keep_every_steps\": 10000,  # Keep permanent checkpoints\n",
        "        \"resume_id\": None,  # Set to run ID to resume training\n",
        "\n",
        "        \"curriculum\": {\n",
        "            \"dims\": {\n",
        "                \"start\": 5,\n",
        "                \"end\": 20,\n",
        "                \"inc\": 1,\n",
        "                \"interval\": 2000,\n",
        "            },\n",
        "            \"points\": {\n",
        "                \"start\": 11,\n",
        "                \"end\": 41,\n",
        "                \"inc\": 2,\n",
        "                \"interval\": 2000,\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"wandb\": {\n",
        "        \"project\": \"cs182-icl-experiments\",\n",
        "        \"entity\": wandb_entity,  # Auto-detected from your login\n",
        "        \"notes\": \"Training on Google Colab\",\n",
        "        \"name\": \"colab_linear_regression\",  # Experiment name\n",
        "        \"log_every_steps\": 10,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Validate entity\n",
        "if config[\"wandb\"][\"entity\"] == \"your-wandb-entity\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"⚠️  WARNING: W&B entity not set!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Update it manually:\")\n",
        "    print(\"  config['wandb']['entity'] = 'your-personal-username'\")\n",
        "    print(\"\\nFind your username at: https://wandb.ai/settings\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(f\"\\n✓ W&B entity set to: {config['wandb']['entity']}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(config[\"out_dir\"], exist_ok=True)\n",
        "\n",
        "# Display configuration\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Configuration:\")\n",
        "print(\"=\"*60)\n",
        "print(yaml.dump(config, default_flow_style=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ko6faJDYJ0a"
      },
      "source": [
        "#5. Traning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "fcU17pCIYJ0a",
        "outputId": "3f42ada1-1116-4daf-b3c1-8c459c7b5832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 42.47 GB\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "\n",
            "\n",
            "❌ Error during training: tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3744848137.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdata_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     task_sampler = get_task_sampler(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mn_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "import uuid\n",
        "from types import SimpleNamespace\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('./src')\n",
        "\n",
        "from train import train, main\n",
        "from models import build_model\n",
        "from eval import get_run_metrics\n",
        "\n",
        "# Convert dict to namespace for compatibility with train.py\n",
        "def dict_to_namespace(d):\n",
        "    namespace = SimpleNamespace()\n",
        "    for key, value in d.items():\n",
        "        if isinstance(value, dict):\n",
        "            setattr(namespace, key, dict_to_namespace(value))\n",
        "        else:\n",
        "            setattr(namespace, key, value)\n",
        "    return namespace\n",
        "\n",
        "args = dict_to_namespace(config)\n",
        "\n",
        "# Generate run ID\n",
        "if not args.test_run:\n",
        "    run_id = args.training.resume_id\n",
        "    if run_id is None:\n",
        "        run_id = str(uuid.uuid4())\n",
        "\n",
        "    out_dir = os.path.join(args.out_dir, run_id)\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "    args.out_dir = out_dir\n",
        "\n",
        "    # Save config\n",
        "    with open(os.path.join(out_dir, \"config.yaml\"), \"w\") as yaml_file:\n",
        "        yaml.dump(config, yaml_file, default_flow_style=False)\n",
        "\n",
        "    print(f\"Run ID: {run_id}\")\n",
        "    print(f\"Output directory: {out_dir}\")\n",
        "\n",
        "# Check CUDA\n",
        "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# import os\n",
        "# os.environ[\"WANDB_DISABLED\"] = \"true\"  # or: os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "\n",
        "# Start training\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    main(args)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"✓ Training completed successfully!\")\n",
        "    print(\"=\"*60)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error during training: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SbS7OC6YJ0a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjvlhBsmYJ0a",
        "outputId": "91de4594-ea29-4faf-e73a-6ef27dbc8895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Model saved to: /content/drive/MyDrive/in-context-learning-models/eb4f3ff9-78ee-4b70-b9c3-1cac60deecf8\n"
          ]
        }
      ],
      "source": [
        "# Mount drive if not already mounted\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Copy model to Drive\n",
        "drive_model_path = '/content/drive/MyDrive/in-context-learning-models'\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "if 'run_id' in locals():\n",
        "    source_dir = os.path.join(config[\"out_dir\"], run_id)\n",
        "    dest_dir = os.path.join(drive_model_path, run_id)\n",
        "\n",
        "    if os.path.exists(source_dir):\n",
        "        shutil.copytree(source_dir, dest_dir, dirs_exist_ok=True)\n",
        "        print(f\"✓ Model saved to: {dest_dir}\")\n",
        "    else:\n",
        "        print(f\"❌ Source directory not found: {source_dir}\")\n",
        "else:\n",
        "    print(\"No run_id found. Make sure training has completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReY167YkYJ0a"
      },
      "source": [
        "## 7. Monitor Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG_YcJrYYJ0a",
        "outputId": "e0506bc2-487f-42f1-e5bf-fd6b053ec13e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No active W&B run. Training may not have started or test_run=True.\n"
          ]
        }
      ],
      "source": [
        "# View W&B dashboard\n",
        "import wandb\n",
        "\n",
        "# Get the W&B run URL\n",
        "if wandb.run is not None:\n",
        "    print(f\"View training progress at: {wandb.run.get_url()}\")\n",
        "else:\n",
        "    print(\"No active W&B run. Training may not have started or test_run=True.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n966HecFYJ0b",
        "outputId": "0e09febf-c684-4fff-f750-7a208b3c8a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoints in ./models/2f65f791-6296-4ca7-a2e5-a53955d36a62:\n",
            "  - config.yaml (0.00 MB)\n",
            "  - wandb (0.00 MB)\n"
          ]
        }
      ],
      "source": [
        "# List saved checkpoints\n",
        "if 'run_id' in locals():\n",
        "    checkpoint_dir = os.path.join(config[\"out_dir\"], run_id)\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        print(f\"Checkpoints in {checkpoint_dir}:\")\n",
        "        for file in sorted(os.listdir(checkpoint_dir)):\n",
        "            filepath = os.path.join(checkpoint_dir, file)\n",
        "            size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "            print(f\"  - {file} ({size_mb:.2f} MB)\")\n",
        "    else:\n",
        "        print(\"Checkpoint directory not found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc46ulqvYJ0b"
      },
      "source": [
        "## 8. Resume Training (Optional)\n",
        "To resume training from a checkpoint, update the configuration and rerun\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDmcB_QlYJ0b"
      },
      "outputs": [],
      "source": [
        "# To resume training, set the resume_id in the config above and rerun section 5:\n",
        "# config[\"training\"][\"resume_id\"] = \"your-run-id-here\"\n",
        "\n",
        "print(\"To resume training:\")\n",
        "print(\"1. Set config['training']['resume_id'] = 'your-run-id'\")\n",
        "print(\"2. Rerun the training cell (Section 5)\")\n",
        "if 'run_id' in locals():\n",
        "    print(f\"\\nCurrent run_id: {run_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia0oiI-gYJ0b"
      },
      "source": [
        "## 9. Quick Test Run\n",
        "Run a quick test to verify everything works (100 steps only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "7sh-l0sLYJ0b",
        "outputId": "c8ee5c51-3288-4709-caba-d82141449646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running quick test (100 steps, no W&B logging)...\n",
            "\n",
            "\n",
            "❌ Test run failed: tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1518453471.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n✓ Test run completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can now run the full training in Section 5.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/train.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdata_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     task_sampler = get_task_sampler(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mn_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tasks.get_task_sampler() argument after ** must be a mapping, not types.SimpleNamespace"
          ]
        }
      ],
      "source": [
        "# Quick test configuration\n",
        "test_config = config.copy()\n",
        "test_config[\"test_run\"] = True\n",
        "test_config[\"training\"] = config[\"training\"].copy()\n",
        "test_config[\"training\"][\"train_steps\"] = 100\n",
        "\n",
        "print(\"Running quick test (100 steps, no W&B logging)...\\n\")\n",
        "\n",
        "test_args = dict_to_namespace(test_config)\n",
        "\n",
        "try:\n",
        "    main(test_args)\n",
        "    print(\"\\n✓ Test run completed successfully!\")\n",
        "    print(\"You can now run the full training in Section 5.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Test run failed: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioOMMwRCYJ0b"
      },
      "source": [
        "## 10. Download Model Files\n",
        "Download trained models to your local machine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4voDQOg_YJ0b"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the final model state\n",
        "if 'run_id' in locals():\n",
        "    state_path = os.path.join(config[\"out_dir\"], run_id, \"state.pt\")\n",
        "    if os.path.exists(state_path):\n",
        "        files.download(state_path)\n",
        "        print(f\"✓ Downloaded: state.pt\")\n",
        "\n",
        "    # Download config\n",
        "    config_path = os.path.join(config[\"out_dir\"], run_id, \"config.yaml\")\n",
        "    if os.path.exists(config_path):\n",
        "        files.download(config_path)\n",
        "        print(f\"✓ Downloaded: config.yaml\")\n",
        "else:\n",
        "    print(\"No trained model found. Complete training first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtxNNdnSYJ0b"
      },
      "source": [
        "## Tips and Troubleshooting\n",
        "\n",
        "### Training Tips:\n",
        "- **GPU Runtime:** Use T4 (free) for smaller models, A100 (Colab Pro) for faster training\n",
        "- **Train Steps:** Start with 10,000-50,000 steps for experiments, 500,000 for full training\n",
        "- **Batch Size:** Reduce if you get OOM (Out of Memory) errors\n",
        "- **Checkpointing:** Models save every `save_every_steps`. You can resume if disconnected\n",
        "- **First Run:** Try the Quick Test Run (Section 9) first to verify everything works\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "**1. Package Installation Errors:**\n",
        "   - The notebook uses modern package versions (PyTorch 2.x) compatible with current Colab\n",
        "   - If you see package conflicts, restart runtime and rerun installation cell\n",
        "   - Some packages may show warnings - these are usually safe to ignore if training works\n",
        "\n",
        "**2. OOM (Out of Memory) Error:**\n",
        "   - Reduce `batch_size` from 64 to 32 or 16\n",
        "   - Reduce `n_embd` from 256 to 128\n",
        "   - Reduce `n_layer` from 12 to 6\n",
        "\n",
        "**3. Slow Training:**\n",
        "   - Ensure GPU is enabled (Runtime → Change runtime type → T4 GPU)\n",
        "   - Check GPU usage with `!nvidia-smi` in a cell\n",
        "\n",
        "**4. Disconnected:**\n",
        "   - Training saves checkpoints automatically\n",
        "   - Copy the `run_id` printed when training starts\n",
        "   - Set `config[\"training\"][\"resume_id\"] = \"your-run-id\"` and rerun Section 5\n",
        "\n",
        "**5. W&B Login Issues:**\n",
        "   - Get your API key from https://wandb.ai/authorize\n",
        "   - You only need to login once per Colab session\n",
        "\n",
        "**6. Repository Clone Issues:**\n",
        "   - Update `REPO_URL` in Section 2 with your actual GitHub URL\n",
        "   - Or use Option B to mount Google Drive and upload files manually\n",
        "\n",
        "### Task Options:\n",
        "- `linear_regression`: Basic linear regression (recommended for first run)\n",
        "- `sparse_linear_regression`: Sparse linear regression\n",
        "- `linear_classification`: Binary classification\n",
        "- `relu_2nn_regression`: 2-layer ReLU network regression\n",
        "- `decision_tree`: Decision tree learning\n",
        "\n",
        "### Model Options:\n",
        "- `gpt2`: Transformer model (recommended, better performance)\n",
        "- `lstm`: LSTM model (alternative, faster but less accurate)\n",
        "\n",
        "### Performance Tips:\n",
        "- **T4 GPU (Free):** ~5-10 minutes per 1000 steps\n",
        "- **A100 GPU (Pro):** ~2-3 minutes per 1000 steps  \n",
        "- **Full training (50k steps):** Expect 4-8 hours on T4\n",
        "- Consider starting with 10,000 steps to verify everything works\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}