{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fKvnLWQrU_Z"
      },
      "source": [
        "# In-Context Learning Training on Google Colab\n",
        "\n",
        "This notebook trains transformer models for in-context learning tasks.\n",
        "\n",
        "**Setup Instructions:**\n",
        "1. Runtime → Change runtime type → GPU (T4, A100, or V100)\n",
        "2. Run cells sequentially\n",
        "3. Authenticate with Weights & Biases when prompted\n",
        "\n",
        "**Note:** This notebook uses the new YAML-based configuration system (no quinine dependency).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of9tdvzPrU_a"
      },
      "source": [
        "## 1. Check GPU and Python Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGCl6Gf1rU_a",
        "outputId": "6c6230a8-82a0-4f73-9bdb-3b2c4b111329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 11 16:37:36 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   42C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import sys\n",
        "print(f\"\\nPython version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfIvzMEOrU_a"
      },
      "source": [
        "## 2. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsx4QluMrU_a",
        "outputId": "81d09832-6b0d-4df5-bdb4-11f8cf053113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing packages...\n",
            "\n",
            "Collecting munch\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: munch\n",
            "Successfully installed munch-4.0.0\n",
            "✓ PyTorch already installed: 2.8.0+cu126\n",
            "\n",
            "============================================================\n",
            "✓ All required packages installed successfully!\n",
            "============================================================\n",
            "\n",
            "Package Versions:\n",
            "  PyTorch: 2.8.0+cu126\n",
            "  Transformers: 4.57.1\n",
            "  Wandb: 0.22.3\n",
            "\n",
            "GPU Information:\n",
            "  CUDA available: True\n",
            "  CUDA version: 12.6\n",
            "  GPU: NVIDIA L4\n",
            "  GPU Memory: 23.80 GB\n",
            "\n",
            "✓ Ready to proceed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"Installing packages...\\n\")\n",
        "\n",
        "# Core ML packages\n",
        "%pip install -q transformers>=4.30.0\n",
        "%pip install -q wandb\n",
        "%pip install -q xgboost\n",
        "%pip install -q matplotlib seaborn tqdm\n",
        "%pip install -q pyyaml\n",
        "%pip install munch\n",
        "\n",
        "# PyTorch usually comes pre-installed in Colab\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"✓ PyTorch already installed: {torch.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Installing PyTorch...\")\n",
        "    %pip install -q torch torchvision torchaudio\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ All required packages installed successfully!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify key packages\n",
        "import torch\n",
        "import transformers\n",
        "import wandb\n",
        "import yaml\n",
        "\n",
        "print(f\"\\nPackage Versions:\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Wandb: {wandb.__version__}\")\n",
        "\n",
        "print(f\"\\nGPU Information:\")\n",
        "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"  ⚠️  No GPU detected! Enable GPU: Runtime → Change runtime type → T4 GPU\")\n",
        "\n",
        "print(\"\\n✓ Ready to proceed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mount at Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/in-context-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03_krESxrU_b"
      },
      "source": [
        "## 3. Clone/Setup Repository\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUjlkJrBrU_b",
        "outputId": "c43cc47a-f0ca-401b-98e4-e5473e2c4970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning repository from https://github.com/hingma/in-context-learning.git...\n",
            "✓ Repository cloned successfully\n",
            "/content/in-context-learning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "REPO_URL = \"https://github.com/hingma/in-context-learning.git\"  # UPDATE THIS!\n",
        "\n",
        "if not os.path.exists(\"in-context-learning\"):\n",
        "    print(f\"Cloning repository from {REPO_URL}...\")\n",
        "    result = subprocess.run([\"git\", \"clone\", REPO_URL], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        print(\"✓ Repository cloned successfully\")\n",
        "    else:\n",
        "        print(f\"Error cloning repository: {result.stderr}\")\n",
        "else:\n",
        "    print(\"✓ Repository already exists\")\n",
        "\n",
        "%cd in-context-learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCzHpZ50rU_b"
      },
      "source": [
        "## 4. Setup Weights & Biases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMAkHefrU_b",
        "outputId": "99821c17-f939-49f4-cfe5-55e09f075957"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoxintang\u001b[0m (\u001b[33mmoxintang-ucb\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ W&B authenticated\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to W&B (you'll need to paste your API key)\n",
        "wandb.login()\n",
        "\n",
        "print(\"✓ W&B authenticated\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADGtp6irU_b"
      },
      "source": [
        "## 5. Configuration Setup\n",
        "\n",
        "Define your training configuration. This replaces the need for external config files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJprfdb7rU_c",
        "outputId": "fa94f1a8-7e1c-40da-dbbf-40f8cb544e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration saved to: train_config.yaml\n",
            "\n",
            "Configuration:\n",
            "model:\n",
            "  family: qwen2.5\n",
            "  n_dims: 20\n",
            "  n_embd: 256\n",
            "  n_head: 8\n",
            "  n_layer: 12\n",
            "  n_positions: 256\n",
            "training:\n",
            "  batch_size: 64\n",
            "  curriculum:\n",
            "    dims:\n",
            "      end: 20\n",
            "      inc: 1\n",
            "      interval: 100\n",
            "      start: 5\n",
            "    points:\n",
            "      end: 41\n",
            "      inc: 1\n",
            "      interval: 100\n",
            "      start: 10\n",
            "  data: gaussian\n",
            "  keep_every_steps: -1\n",
            "  learning_rate: 0.0003\n",
            "  num_tasks: null\n",
            "  num_training_examples: null\n",
            "  resume_id: null\n",
            "  save_every_steps: 1000\n",
            "  task: linear_regression\n",
            "  task_kwargs: {}\n",
            "  train_steps: 10000\n",
            "wandb:\n",
            "  entity: null\n",
            "  log_every_steps: 10\n",
            "  name: null\n",
            "  notes: Training run from Colab\n",
            "  project: qwen-linear-in-context-training\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "# Define your configuration\n",
        "config = {\n",
        "    'model': {\n",
        "        'family': 'qwen2.5',  # Options: 'gpt2' or 'lstm'\n",
        "        'n_positions': 256,  # Maximum context length\n",
        "        'n_dims': 20,  # Latent dimension\n",
        "        'n_embd': 256,  # Embedding dimension\n",
        "        'n_layer': 12,  # Number of layers\n",
        "        'n_head': 8,  # Number of attention heads\n",
        "    },\n",
        "    'training': {\n",
        "        'task': 'linear_regression',  # Task type\n",
        "        # Options: linear_regression, sparse_linear_regression,\n",
        "        #          linear_classification, relu_2nn_regression, decision_tree\n",
        "        'task_kwargs': {},  # Task-specific arguments\n",
        "        'num_tasks': None,  # Number of tasks (None = unlimited)\n",
        "        'num_training_examples': None,  # Training examples (None = unlimited)\n",
        "        'data': 'gaussian',  # Data distribution\n",
        "        'batch_size': 64,  # Batch size\n",
        "        'learning_rate': 3e-4,  # Learning rate\n",
        "        'train_steps': 10000,  # Total training steps\n",
        "        'save_every_steps': 1000,  # Checkpoint frequency\n",
        "        'keep_every_steps': -1,  # Permanent checkpoint frequency (-1 = disabled)\n",
        "        'resume_id': None,  # Resume from run ID (None = new run)\n",
        "        'curriculum': {\n",
        "            'dims': {\n",
        "                'start': 5,  # Initial dimensions\n",
        "                'end': 20,  # Final dimensions\n",
        "                'inc': 1,  # Increment per update\n",
        "                'interval': 100,  # Update every N steps\n",
        "            },\n",
        "            'points': {\n",
        "                'start': 10,  # Initial points\n",
        "                'end': 41,  # Final points\n",
        "                'inc': 1,  # Increment per update\n",
        "                'interval': 100,  # Update every N steps\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    'wandb': {\n",
        "    'project': 'qwen-linear-ICL-full-sample',\n",
        "    'entity': None,  # ← Use your default entity\n",
        "    'notes': 'Training run from Colab',\n",
        "    'name': None,\n",
        "    'log_every_steps': 10,\n",
        "    },\n",
        "    # 'wandb': {\n",
        "    #     'project': 'in-context-training',  # W&B project name\n",
        "    #     'entity': 'moxintang',  # W&B entity/team name - UPDATE THIS!\n",
        "    #     'notes': 'Training run from Colab',  # Run notes\n",
        "    #     'name': None,  # Run name (None = auto-generated)\n",
        "    #     'log_every_steps': 10,  # Logging frequency\n",
        "    # },\n",
        "}\n",
        "\n",
        "# Save config to file\n",
        "config_path = 'train_config.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f, default_flow_style=False)\n",
        "\n",
        "print(\"Configuration saved to:\", config_path)\n",
        "print(\"\\nConfiguration:\")\n",
        "print(yaml.dump(config, default_flow_style=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__bcoYGSrU_c"
      },
      "source": [
        "## 6. Import Training Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s-092ByrU_c",
        "outputId": "fae33167-6e7e-4b6a-ec49-e177bd4739f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ All modules imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Add src to path\n",
        "import sys\n",
        "sys.path.insert(0, './src')\n",
        "\n",
        "# Import required modules\n",
        "import torch\n",
        "from random import randint\n",
        "import uuid\n",
        "from tqdm import tqdm\n",
        "\n",
        "from eval import get_run_metrics\n",
        "from tasks import get_task_sampler\n",
        "from samplers import get_data_sampler\n",
        "from curriculum import Curriculum\n",
        "from models import build_model\n",
        "from config import ConfigDict, validate_config, set_defaults\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"✓ All modules imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSKNTDtErU_c"
      },
      "source": [
        "## 7. Define Training Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXdNYFgHrU_c",
        "outputId": "ca57531b-a9d8-4e9d-d91c-4ebd0e7b666b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Training functions defined\n"
          ]
        }
      ],
      "source": [
        "def train_step(model, xs, ys, optimizer, loss_func):\n",
        "    \"\"\"Execute a single training step.\"\"\"\n",
        "    optimizer.zero_grad()\n",
        "    output = model(xs, ys)\n",
        "    loss = loss_func(output, ys)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.detach().item(), output.detach()\n",
        "\n",
        "\n",
        "def sample_seeds(total_seeds, count):\n",
        "    \"\"\"Sample random seeds for reproducible training examples.\"\"\"\n",
        "    seeds = set()\n",
        "    while len(seeds) < count:\n",
        "        seeds.add(randint(0, total_seeds - 1))\n",
        "    return seeds\n",
        "\n",
        "\n",
        "def train(model, args):\n",
        "    \"\"\"Main training loop.\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.training.learning_rate)\n",
        "    curriculum = Curriculum(args.training.curriculum)\n",
        "\n",
        "    starting_step = 0\n",
        "    state_path = os.path.join(args.out_dir, \"state.pt\")\n",
        "    if os.path.exists(state_path):\n",
        "        state = torch.load(state_path)\n",
        "        model.load_state_dict(state[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
        "        starting_step = state[\"train_step\"]\n",
        "        for i in range(state[\"train_step\"] + 1):\n",
        "            curriculum.update()\n",
        "        print(f\"✓ Resumed from step {starting_step}\")\n",
        "\n",
        "    n_dims = model.n_dims\n",
        "    bsize = args.training.batch_size\n",
        "    data_sampler = get_data_sampler(args.training.data, n_dims=n_dims)\n",
        "    task_sampler = get_task_sampler(\n",
        "        args.training.task,\n",
        "        n_dims,\n",
        "        bsize,\n",
        "        num_tasks=args.training.num_tasks,\n",
        "        **args.training.task_kwargs,\n",
        "    )\n",
        "    pbar = tqdm(range(starting_step, args.training.train_steps))\n",
        "\n",
        "    num_training_examples = args.training.num_training_examples\n",
        "\n",
        "    for i in pbar:\n",
        "        data_sampler_args = {}\n",
        "        task_sampler_args = {}\n",
        "\n",
        "        if \"sparse\" in args.training.task:\n",
        "            task_sampler_args[\"valid_coords\"] = curriculum.n_dims_truncated\n",
        "        if num_training_examples is not None:\n",
        "            assert num_training_examples >= bsize\n",
        "            seeds = sample_seeds(num_training_examples, bsize)\n",
        "            data_sampler_args[\"seeds\"] = seeds\n",
        "            task_sampler_args[\"seeds\"] = [s + 1 for s in seeds]\n",
        "\n",
        "        xs = data_sampler.sample_xs(\n",
        "            curriculum.n_points,\n",
        "            bsize,\n",
        "            curriculum.n_dims_truncated,\n",
        "            **data_sampler_args,\n",
        "        )\n",
        "        task = task_sampler(**task_sampler_args)\n",
        "        ys = task.evaluate(xs)\n",
        "\n",
        "        loss_func = task.get_training_metric()\n",
        "\n",
        "        loss, output = train_step(model, xs.cuda(), ys.cuda(), optimizer, loss_func)\n",
        "\n",
        "        point_wise_tags = list(range(curriculum.n_points))\n",
        "        point_wise_loss_func = task.get_metric()\n",
        "        point_wise_loss = point_wise_loss_func(output, ys.cuda()).mean(dim=0)\n",
        "\n",
        "        baseline_loss = (\n",
        "            sum(\n",
        "                max(curriculum.n_dims_truncated - ii, 0)\n",
        "                for ii in range(curriculum.n_points)\n",
        "            )\n",
        "            / curriculum.n_points\n",
        "        )\n",
        "\n",
        "        if i % args.wandb.log_every_steps == 0 and not args.test_run:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"overall_loss\": loss,\n",
        "                    \"excess_loss\": loss / baseline_loss,\n",
        "                    \"pointwise/loss\": dict(\n",
        "                        zip(point_wise_tags, point_wise_loss.cpu().numpy())\n",
        "                    ),\n",
        "                    \"n_points\": curriculum.n_points,\n",
        "                    \"n_dims\": curriculum.n_dims_truncated,\n",
        "                },\n",
        "                step=i,\n",
        "            )\n",
        "\n",
        "        curriculum.update()\n",
        "\n",
        "        pbar.set_description(f\"loss {loss:.4f}\")\n",
        "        if i % args.training.save_every_steps == 0 and not args.test_run:\n",
        "            training_state = {\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"train_step\": i,\n",
        "            }\n",
        "            torch.save(training_state, state_path)\n",
        "\n",
        "        if (\n",
        "            args.training.keep_every_steps > 0\n",
        "            and i % args.training.keep_every_steps == 0\n",
        "            and not args.test_run\n",
        "            and i > 0\n",
        "        ):\n",
        "            torch.save(model.state_dict(), os.path.join(args.out_dir, f\"model_{i}.pt\"))\n",
        "\n",
        "    print(\"\\n✓ Training completed!\")\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    \"\"\"Main training function.\"\"\"\n",
        "    if args.test_run:\n",
        "        curriculum_args = args.training.curriculum\n",
        "        curriculum_args['points']['start'] = curriculum_args['points']['end']\n",
        "        curriculum_args['dims']['start'] = curriculum_args['dims']['end']\n",
        "        args.training.train_steps = 100\n",
        "        print(\"Running in test mode (100 steps)\")\n",
        "    else:\n",
        "        wandb.init(\n",
        "            project=args.wandb.project,\n",
        "            config=dict(args),\n",
        "            notes=args.wandb.notes,\n",
        "            name=args.wandb.name,\n",
        "        )\n",
        "        # wandb.init(\n",
        "        #     dir=args.out_dir,\n",
        "        #     project=args.wandb.project,\n",
        "        #     entity=args.wandb.entity,\n",
        "        #     config=dict(args),\n",
        "        #     notes=args.wandb.notes,\n",
        "        #     name=args.wandb.name,\n",
        "        #     resume=True,\n",
        "        # )\n",
        "        print(f\"✓ W&B run initialized: {wandb.run.name}\")\n",
        "\n",
        "    model = build_model(args.model)\n",
        "    model.cuda()\n",
        "    model.train()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Model: {args.model.family}\")\n",
        "    print(f\"Task: {args.training.task}\")\n",
        "    print(f\"Training steps: {args.training.train_steps}\")\n",
        "    print(f\"Batch size: {args.training.batch_size}\")\n",
        "    print(f\"Learning rate: {args.training.learning_rate}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    train(model, args)\n",
        "\n",
        "    if not args.test_run:\n",
        "        _ = get_run_metrics(args.out_dir)  # Precompute metrics for eval\n",
        "        print(\"✓ Metrics computed\")\n",
        "\n",
        "\n",
        "print(\"✓ Training functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Model Evaluation\n",
        "\n",
        "Evaluate your trained qwen2.5 model on various test scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix for device compatibility - ensure model is properly on CUDA\n",
        "# This cell loads your trained model for evaluation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Specify your trained model's run_id\n",
        "run_id = \"8a53116d-8c44-4687-9af4-bc8344eafbc7\"  # Update this with your actual run_id\n",
        "run_path = os.path.join(\"./outputs\", run_id)\n",
        "\n",
        "# Load model and config\n",
        "from eval import get_model_from_run\n",
        "model, conf = get_model_from_run(run_path)\n",
        "\n",
        "# Move model to CUDA and set to eval mode\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    print(f\"✓ Model loaded on GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"⚠️  Running on CPU (slower)\")\n",
        "    \n",
        "model.eval()\n",
        "\n",
        "print(f\"\\nModel Configuration:\")\n",
        "print(f\"  Family: {conf.model.family}\")\n",
        "print(f\"  Task: {conf.training.task}\")\n",
        "print(f\"  n_dims: {conf.model.n_dims}\")\n",
        "print(f\"  n_layer: {conf.model.n_layer}\")\n",
        "print(f\"  n_head: {conf.model.n_head}\")\n",
        "print(f\"  n_positions: {conf.model.n_positions}\")\n",
        "print(f\"\\n✓ Model ready for evaluation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate test data and evaluate model\n",
        "\n",
        "# Sample task and data\n",
        "task = task_sampler()\n",
        "xs = data_sampler.sample_xs(b_size=batch_size, n_points=n_points)\n",
        "ys = task.evaluate(xs)\n",
        "\n",
        "print(f\"Generated test data:\")\n",
        "print(f\"  xs shape: {xs.shape}  (batch_size, n_points, n_dims)\")\n",
        "print(f\"  ys shape: {ys.shape}  (batch_size, n_points)\")\n",
        "\n",
        "# Get model predictions\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "with torch.no_grad():\n",
        "    pred = model(xs.to(device), ys.to(device))\n",
        "    pred = pred.cpu()  # Move back to CPU for metric computation\n",
        "\n",
        "print(f\"  pred shape: {pred.shape}\")\n",
        "\n",
        "# Compute loss\n",
        "metric = task.get_metric()\n",
        "loss = metric(pred, ys).numpy()\n",
        "\n",
        "print(f\"\\nPrediction statistics:\")\n",
        "print(f\"  Mean loss: {loss.mean():.4f}\")\n",
        "print(f\"  Final point mean loss: {loss[:, -1].mean():.4f}\")\n",
        "print(f\"\\n✓ Evaluation complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize in-context learning performance\n",
        "\n",
        "# Calculate baseline (zero estimator)\n",
        "sparsity = conf.training.task_kwargs.sparsity if \"sparsity\" in conf.training.task_kwargs else None\n",
        "baseline = {\n",
        "    \"linear_regression\": n_dims,\n",
        "    \"sparse_linear_regression\": sparsity,\n",
        "    \"relu_2nn_regression\": n_dims,\n",
        "    \"decision_tree\": 1,\n",
        "}[conf.training.task]\n",
        "\n",
        "# Plot learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss.mean(axis=0), lw=2, label=f\"{conf.model.family} (qwen2.5)\", marker='o', markersize=3)\n",
        "plt.axhline(baseline, ls=\"--\", color=\"gray\", label=\"Zero estimator baseline\")\n",
        "plt.xlabel(\"# in-context examples\", fontsize=12)\n",
        "plt.ylabel(\"Squared error\", fontsize=12)\n",
        "plt.title(f\"In-Context Learning Performance: {conf.training.task}\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Baseline loss: {baseline:.2f}\")\n",
        "print(f\"Final mean loss: {loss[:, -1].mean():.4f}\")\n",
        "print(f\"Improvement: {(1 - loss[:, -1].mean() / baseline) * 100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comprehensive evaluation results\n",
        "\n",
        "import json\n",
        "\n",
        "# Load metrics\n",
        "metrics_path = os.path.join(run_path, \"metrics.json\")\n",
        "if os.path.exists(metrics_path):\n",
        "    with open(metrics_path, 'r') as f:\n",
        "        all_metrics = json.load(f)\n",
        "    \n",
        "    model_name = f\"{conf.model.family}_qwen2.5\"\n",
        "    \n",
        "    # Plot standard evaluation\n",
        "    if \"standard\" in all_metrics:\n",
        "        standard_metrics = all_metrics[\"standard\"]\n",
        "        \n",
        "        plt.figure(figsize=(12, 6))\n",
        "        \n",
        "        # Plot model performance\n",
        "        if model_name in standard_metrics:\n",
        "            means = standard_metrics[model_name][\"mean\"]\n",
        "            plt.plot(means, lw=2, label=f\"Qwen2.5 ({conf.model.n_layer}L)\", marker='o', markersize=4)\n",
        "        \n",
        "        # Plot baselines if available\n",
        "        baseline_models = [\"OLS\", \"averaging\", \"NN_n=1\", \"NN_n=3\"]\n",
        "        colors = plt.cm.Set2(range(len(baseline_models)))\n",
        "        \n",
        "        for i, baseline_name in enumerate(baseline_models):\n",
        "            if baseline_name in standard_metrics:\n",
        "                means = standard_metrics[baseline_name][\"mean\"]\n",
        "                plt.plot(means, lw=1.5, label=baseline_name, alpha=0.7, linestyle='--', color=colors[i])\n",
        "        \n",
        "        plt.xlabel(\"# in-context examples\", fontsize=12)\n",
        "        plt.ylabel(\"Squared error\", fontsize=12)\n",
        "        plt.title(\"Standard Evaluation: Model vs Baselines\", fontsize=14)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"✓ Standard evaluation plotted\")\n",
        "    \n",
        "    # Show summary of all evaluations\n",
        "    print(f\"\\nEvaluation Summary:\")\n",
        "    print(f\"{'Scenario':<30} {'Final Loss':<15}\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    for eval_name, metrics in all_metrics.items():\n",
        "        if model_name in metrics:\n",
        "            final_loss = metrics[model_name][\"mean\"][-1]\n",
        "            print(f\"{eval_name:<30} {final_loss:>10.4f}\")\n",
        "        elif list(metrics.keys()):\n",
        "            # Use first available model\n",
        "            first_model = list(metrics.keys())[0]\n",
        "            final_loss = metrics[first_model][\"mean\"][-1]\n",
        "            print(f\"{eval_name:<30} {final_loss:>10.4f} ({first_model})\")\n",
        "else:\n",
        "    print(\"⚠️  Metrics file not found. Run the comprehensive evaluation cell first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfLDnQg3rU_d"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K6RnEPVrU_d",
        "outputId": "a93f6de1-d6f4-4b2e-d323-ed760ca6b9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Output directory: ./outputs/8a53116d-8c44-4687-9af4-bc8344eafbc7\n",
            "✓ Run ID: 8a53116d-8c44-4687-9af4-bc8344eafbc7\n",
            "\n",
            "✓ Configuration prepared\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare configuration\n",
        "with open(config_path, 'r') as f:\n",
        "    config_dict = yaml.safe_load(f)\n",
        "\n",
        "# Set defaults and validate\n",
        "set_defaults(config_dict)\n",
        "validate_config(config_dict)\n",
        "\n",
        "# Add required fields\n",
        "config_dict['out_dir'] = './outputs'  # Output directory\n",
        "config_dict['test_run'] = False  # Set to True for quick test run (100 steps)\n",
        "\n",
        "config_dict['training']['resume_id'] = '8a53116d-8c44-4687-9af4-bc8344eafbc7'\n",
        "\n",
        "# Convert to ConfigDict for attribute access\n",
        "args = ConfigDict(config_dict)\n",
        "\n",
        "# Verify model family\n",
        "assert args.model.family in [\"gpt2\", \"lstm\", \"qwen2.5\"], f\"Invalid model family: {args.model.family}\"\n",
        "\n",
        "# Create output directory with unique run ID\n",
        "if not args.test_run:\n",
        "    run_id = args.training.resume_id\n",
        "    if run_id is None:\n",
        "        run_id = str(uuid.uuid4())\n",
        "\n",
        "    out_dir = os.path.join(args.out_dir, run_id)\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "    args.out_dir = out_dir\n",
        "\n",
        "    # Save config to output directory\n",
        "    with open(os.path.join(out_dir, \"config.yaml\"), \"w\") as yaml_file:\n",
        "        yaml.dump(dict(args), yaml_file, default_flow_style=False)\n",
        "\n",
        "    print(f\"✓ Output directory: {out_dir}\")\n",
        "    print(f\"✓ Run ID: {run_id}\")\n",
        "else:\n",
        "    print(\"Running in test mode (no output saved)\")\n",
        "\n",
        "print(\"\\n✓ Configuration prepared\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0KovRZVACMV",
        "outputId": "4811ef31-2cc6-4bf1-99e3-7650598d0a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8a53116d-8c44-4687-9af4-bc8344eafbc7\n"
          ]
        }
      ],
      "source": [
        "print(args.training.resume_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdecmyhnrU_d"
      },
      "source": [
        "## 9. Start Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jNFsyPdoA0gh"
      },
      "outputs": [],
      "source": [
        "import eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kgd8oxeirU_d",
        "outputId": "d996fbf7-bb95-4c43-f0fa-e87ae6e892b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>excess_loss</td><td>▅▅▄▆▅▇▅▄▅▇▃▆▅▃▅▆▃█▄▁▆▄▅▅▅▄▄▅▂▇▅▇▆█▁▆▅▅▅▅</td></tr><tr><td>n_dims</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>overall_loss</td><td>▄▅▆▄▅▅▄▂▆▄▄▆▇▃▅▇▆▇▆▅▆▁▆▄▄▆▅▄▆▆▂▇▅▅▁▅█▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>excess_loss</td><td>1.08336</td></tr><tr><td>n_dims</td><td>20</td></tr><tr><td>n_points</td><td>41</td></tr><tr><td>overall_loss</td><td>5.5489</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">elated-cosmos-3</strong> at: <a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training/runs/fjhjjapu' target=\"_blank\">https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training/runs/fjhjjapu</a><br> View project at: <a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training' target=\"_blank\">https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251111_173944-fjhjjapu/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/in-context-learning/wandb/run-20251111_174255-5p5aml7y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training/runs/5p5aml7y' target=\"_blank\">sweet-cosmos-4</a></strong> to <a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training' target=\"_blank\">https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training/runs/5p5aml7y' target=\"_blank\">https://wandb.ai/moxintang-ucb/qwen-linear-in-context-training/runs/5p5aml7y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ W&B run initialized: sweet-cosmos-4\n",
            "\n",
            "============================================================\n",
            "Model: qwen2.5\n",
            "Task: linear_regression\n",
            "Training steps: 10000\n",
            "Batch size: 64\n",
            "Learning rate: 0.0003\n",
            "============================================================\n",
            "\n",
            "✓ Resumed from step 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 5.6400: 100%|██████████| 1000/1000 [01:37<00:00, 10.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Training completed!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3647046295.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3709125583.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_run_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Precompute metrics for eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Metrics computed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/eval.py\u001b[0m in \u001b[0;36mget_run_metrics\u001b[0;34m(run_path, step, cache, skip_model_load, skip_baselines)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mrecompute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mall_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_evals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecompute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/eval.py\u001b[0m in \u001b[0;36mcompute_evals\u001b[0;34m(all_models, evaluation_kwargs, save_path, recompute)\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mall_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/eval.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, task_name, data_name, n_dims, n_points, prompting_strategy, num_eval_examples, batch_size, data_sampler_kwargs, task_sampler_kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerating_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mall_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/eval.py\u001b[0m in \u001b[0;36meval_batch\u001b[0;34m(model, task_sampler, xs, xs_p)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxs_p\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/in-context-learning/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ys, inds)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inds contain indices where xs and ys are not defined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "# Run training\n",
        "print(\"Starting training...\\n\")\n",
        "main(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvyfgZu1rU_d"
      },
      "source": [
        "## 11. Save/Download Model\n",
        "\n",
        "After training completes, you can download the model checkpoints:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "T40epdVirU_d",
        "outputId": "89ae4dbe-b06e-44c5-eb49-578f7fd544d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ./outputs/8a53116d-8c44-4687-9af4-bc8344eafbc7/state.pt...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cffecbd1-a1c9-4630-9f9e-f80e8e4cf816\", \"state.pt\", 151406687)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ./outputs/8a53116d-8c44-4687-9af4-bc8344eafbc7/config.yaml...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_aa664b76-858e-445e-90ff-96c98b4cf333\", \"config.yaml\", 710)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model files downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download trained model to local machine\n",
        "from google.colab import files\n",
        "\n",
        "# Download the final state\n",
        "if not args.test_run:\n",
        "    state_file = os.path.join(args.out_dir, \"state.pt\")\n",
        "    if os.path.exists(state_file):\n",
        "        print(f\"Downloading {state_file}...\")\n",
        "        files.download(state_file)\n",
        "\n",
        "    # Also download the config\n",
        "    config_file = os.path.join(args.out_dir, \"config.yaml\")\n",
        "    if os.path.exists(config_file):\n",
        "        print(f\"Downloading {config_file}...\")\n",
        "        files.download(config_file)\n",
        "\n",
        "    print(\"✓ Model files downloaded\")\n",
        "else:\n",
        "    print(\"Test run - no files to download\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kns5x22yrU_e"
      },
      "source": [
        "## 12. Optional: Run Quick Test\n",
        "\n",
        "Run a quick test with just 100 steps to verify everything works:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGHNeVVYrU_e"
      },
      "outputs": [],
      "source": [
        "# Quick test run (100 steps, no logging)\n",
        "test_config = config_dict.copy()\n",
        "test_config['test_run'] = True\n",
        "test_args = ConfigDict(test_config)\n",
        "\n",
        "print(\"Running quick test (100 steps)...\\n\")\n",
        "main(test_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGVA0tAsrU_e"
      },
      "source": [
        "## Configuration Options Reference\n",
        "\n",
        "### Model Configuration\n",
        "- `family`: 'gpt2' or 'lstm'\n",
        "- `n_positions`: Maximum sequence length\n",
        "- `n_dims`: Latent dimension size\n",
        "- `n_embd`: Embedding dimension\n",
        "- `n_layer`: Number of transformer/LSTM layers\n",
        "- `n_head`: Number of attention heads (for GPT-2)\n",
        "\n",
        "### Training Tasks\n",
        "Available tasks:\n",
        "1. `linear_regression`: Linear regression\n",
        "2. `sparse_linear_regression`: Sparse linear regression\n",
        "3. `linear_classification`: Linear classification\n",
        "4. `relu_2nn_regression`: 2-layer ReLU neural network regression\n",
        "5. `decision_tree`: Decision tree learning\n",
        "\n",
        "### Curriculum Learning\n",
        "- `start`: Initial value\n",
        "- `end`: Final value\n",
        "- `inc`: Increment per update\n",
        "- `interval`: Update frequency (steps)\n",
        "\n",
        "### Training Parameters\n",
        "- `batch_size`: Batch size (default: 64)\n",
        "- `learning_rate`: Learning rate (default: 3e-4)\n",
        "- `train_steps`: Total training steps\n",
        "- `save_every_steps`: Checkpoint frequency\n",
        "- `keep_every_steps`: Permanent checkpoint frequency (-1 to disable)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
